{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU') # чтобы подтвердить, что TensorFlow использует графический процессор.\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "import os\n",
    "import glob\n",
    "from fr_utils import *\n",
    "from inception_blocks_v2 import *\n",
    "from utils import *\n",
    "from keras import backend as K\n",
    "# from keras.models import load_model\n",
    "\n",
    "# encoder_model = 'facenet_keras.h5'\n",
    "from sklearn.preprocessing import Normalizer\n",
    "l2_normalizer = Normalizer('l2')\n",
    "\n",
    "face_detector = MTCNN()\n",
    "# face_encoder = load_model(encoder_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PADDING = 50\n",
    "ready_to_detect_identity = True\n",
    "\n",
    "K.set_image_data_format('channels_first')\n",
    "FRmodel = faceRecoModel(input_shape=(3, 96, 96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(y_true, y_pred, alpha = 0.3):\n",
    "    anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]\n",
    "\n",
    "    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor,\n",
    "               positive)), axis=-1)\n",
    "    neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, \n",
    "               negative)), axis=-1)\n",
    "    basic_loss = tf.add(tf.subtract(pos_dist, neg_dist), alpha)\n",
    "    loss = tf.reduce_sum(tf.maximum(basic_loss, 0.0))\n",
    "   \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRmodel.compile(optimizer = 'adam', loss = triplet_loss, metrics = ['accuracy'])\n",
    "load_weights_from_FaceNet(FRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "courteney\n",
      "kudrow\n",
      "leblanc\n",
      "matthew\n",
      "schwimmer\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "# from utils import get_face, get_encode, l2_normalizer, normalize\n",
    "\n",
    "# hyper-parameters\n",
    "# encoder_model = 'data/model/facenet_keras.h5'\n",
    "people_dir = 'dataset/friends'\n",
    "encodings_path = 'encodings/encodings.pkl'\n",
    "required_size = (96, 96)\n",
    "\n",
    "# face_detector = mtcnn.MTCNN()\n",
    "# face_encoder = load_model(encoder_model)\n",
    "\n",
    "encoding_dict = dict()      \n",
    "\n",
    "\n",
    "for person_name in os.listdir(people_dir):\n",
    "    person_dir = os.path.join(people_dir, person_name)\n",
    "    encodes = []\n",
    "    for img_name in os.listdir(person_dir):\n",
    "        img_path = os.path.join(person_dir, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        results = face_detector.detect_faces(img_rgb)\n",
    "        if results:\n",
    "            res = max(results, key=lambda b: b['box'][2] * b['box'][3])\n",
    "            face, _, _ = get_face(img_rgb, res['box'])\n",
    "\n",
    "            face = normalize(face)\n",
    "            face = cv2.resize(face, required_size)\n",
    "            \n",
    "            img = face[...,::-1]\n",
    "            img = np.around(np.transpose(img, (2,0,1))/255.0, decimals=12)\n",
    "            x_train = np.array([img])\n",
    "            encode = FRmodel.predict_on_batch(x_train)\n",
    "    \n",
    "#             encode = face_encoder.predict(np.expand_dims(face, axis=0))[0]\n",
    "            encodes.append(encode)\n",
    "            \n",
    "    \n",
    "    if encodes:\n",
    "        \n",
    "        encode = np.sum(encodes, axis=0)\n",
    "        \n",
    "#         print(encode.shape)\n",
    "#         nsamples, nx, ny = encode.shape\n",
    "#         d2_encode = encode.reshape((nsamples,nx * ny))\n",
    "        \n",
    "        encode = l2_normalizer.transform(np.expand_dims(encode, axis=0)[0])[0]\n",
    "        encoding_dict[person_name] = encode\n",
    "\n",
    "\n",
    "for key in encoding_dict.keys():\n",
    "    print(key)\n",
    "\n",
    "with open(encodings_path, 'bw') as file:\n",
    "    pickle.dump(encoding_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encode(model, face, size):\n",
    "    face = normalize(face)\n",
    "    face = cv2.resize(face, size)\n",
    "#     encode = face_encoder.predict(np.expand_dims(face, axis=0))[0]\n",
    "    \n",
    "    img = face[...,::-1]\n",
    "    img = np.around(np.transpose(img, (2,0,1))/255.0, decimals=12)\n",
    "    x_train = np.array([img])\n",
    "    encode = model.predict_on_batch(x_train)\n",
    "    \n",
    "    return encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_face(img, box):\n",
    "#     x1, y1, width, height = box\n",
    "#     x1, y1 = abs(x1), abs(y1)\n",
    "#     x2, y2 = x1 + width, y1 + height\n",
    "#     face = img[y1:y2, x1:x2]\n",
    "#     return face, (x1, y1), (x2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "def recognize(img,\n",
    "              detector,\n",
    "              encoder,\n",
    "              encoding_dict,\n",
    "              recognition_t=0.5,\n",
    "              confidence_t=0.95,\n",
    "              required_size=(96, 96),):\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    results = face_detector.detect_faces(img_rgb)\n",
    "    for res in results:\n",
    "        if res['confidence'] < confidence_t:\n",
    "            continue\n",
    "        face, pt_1, pt_2 = get_face(img_rgb, res['box'])\n",
    "        encode = get_encode(encoder, face, required_size)\n",
    "        encode = l2_normalizer.transform(encode.reshape(1, -1))[0]\n",
    "        name = 'unknown'\n",
    "        \n",
    "\n",
    "        \n",
    "#             dist = np.linalg.norm(encoding-database[name])\n",
    "#             if dist < min_dist:\n",
    "#                 min_dist = dist\n",
    "#                 identity = name\n",
    "\n",
    "        distance = float(\"inf\")\n",
    "        for db_name, db_encode in encoding_dict.items():\n",
    "            dist = np.linalg.norm(encode-db_encode)\n",
    "#             dist = cosine(db_encode, encode)\n",
    "            if dist < recognition_t and dist < distance:\n",
    "                name = db_name\n",
    "                distance = dist\n",
    "\n",
    "        if name == 'unknown':\n",
    "            cv2.rectangle(img, pt_1, pt_2, (0, 0, 255), 1)\n",
    "            cv2.putText(img, name, pt_1, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "        else:\n",
    "            cv2.rectangle(img, pt_1, pt_2, (0, 255, 0), 1)\n",
    "            cv2.putText(img, name + f'-{distance:.3f}', (pt_1[0], pt_1[1] - 15), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                        (0, 200, 100), 1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder_model = 'data/model/facenet_keras.h5'\n",
    "encodings_path = 'encodings/encodings.pkl'\n",
    "\n",
    "# detector = mtcnn.MTCNN()\n",
    "# face_encoder = load_model(encoder_model)\n",
    "encoding_dict = load_pickle(encodings_path)\n",
    "\n",
    "vc = cv2.VideoCapture('dataset/friends.mp4')\n",
    "while vc.isOpened():\n",
    "    ret, frame = vc.read()\n",
    "    if not ret:\n",
    "        print(\"no frame:(\")\n",
    "        break\n",
    "    frame = recognize(frame, face_detector, FRmodel, encoding_dict)\n",
    "    cv2.imshow('camera', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def img_to_encoding_dataset(image_path, model):\n",
    "    \n",
    "#     image = cv2.imread(image_path, 1)\n",
    "#     face = detector.detect_faces(image)\n",
    "    \n",
    "#     x1, y1, x2, y2 = face[0]['box']\n",
    "        \n",
    "#     image = image[y1:y1 + y2, x1:x1 + x2]  \n",
    "#     image = normalize(image)\n",
    "#     image = cv2.resize(image, (96, 96)) \n",
    "    \n",
    "#     cv2.imshow('image', image) \n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows() \n",
    "    \n",
    "#     img = image[...,::-1]\n",
    "#     img = np.around(np.transpose(img, (2,0,1))/255.0, decimals=12)\n",
    "#     x_train = np.array([img])\n",
    "#     embedding = model.predict_on_batch(x_train)\n",
    "#     return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# people_dir = 'dataset/friends'\n",
    "# database = {}\n",
    "\n",
    "# for person_name in os.listdir(people_dir):\n",
    "#     person_dir = os.path.join(people_dir, person_name)\n",
    "#     for img_name in os.listdir(person_dir):\n",
    "#         img_path = os.path.join(person_dir, img_name)\n",
    "#         database[person_name] = img_to_encoding_dataset(img_path, FRmodel)\n",
    "\n",
    "# # for file in glob.glob(\"dataset/friends/*\"):\n",
    "    \n",
    "# #     identity = os.path.splitext(os.path.basename(file))[0]\n",
    "# #     database[identity] = img_to_encoding_dataset(file, FRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def img_to_encoding(image, model):\n",
    "\n",
    "#     image = normalize(image)\n",
    "#     image = cv2.resize(image, (96, 96)) \n",
    "#     img = image[...,::-1]\n",
    "#     img = np.around(np.transpose(img, (2,0,1))/255.0, decimals=12)\n",
    "#     x_train = np.array([img])\n",
    "#     embedding = model.predict_on_batch(x_train)\n",
    "#     return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_identity(frame, x1, y1, x2, y2):\n",
    "\n",
    "#     frame = frame[y1:y2, x1:x2]\n",
    "\n",
    "#     return who_is_it(frame, database, FRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def who_is_it(image_path, database, model):\n",
    "    \n",
    "#     encoding = img_to_encoding(image_path, model)\n",
    "#     min_dist = 100\n",
    "    \n",
    "#     for (name, db_enc) in database.items():\n",
    "        \n",
    "#         dist = np.linalg.norm(encoding-database[name])\n",
    "#         if dist < min_dist:\n",
    "#             min_dist = dist\n",
    "#             identity = name\n",
    "    \n",
    "# #     if min_dist > 0.7:\n",
    "# #         print(\"Not in the database.\")\n",
    "# #     else:\n",
    "# #         print (\"it's \" + str(identity) + \", the distance is \" + str(min_dist))\n",
    "        \n",
    "#     return min_dist, identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# puth = 'dataset/friends.mp4'\n",
    "\n",
    "# video_capture = cv2.VideoCapture(puth)\n",
    "\n",
    "# while video_capture.isOpened():\n",
    "\n",
    "#     _, frame = video_capture.read()\n",
    "#     image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#     faces = detector.detect_faces(image)\n",
    "    \n",
    "#     for face in faces:\n",
    "        \n",
    "#         x1, y1, x2, y2 = face['box']\n",
    "#         x2 = x1+x2\n",
    "#         y2 = y1+y2\n",
    "#         min_dist, identity = find_identity(frame, x1, y1, x2, y2)\n",
    "#         cv2.rectangle(frame, (x1, y1), (x2, y2), (0,0,255), 1)\n",
    "        \n",
    "#         cv2.putText(frame, str(float('{:.4f}'.format(min_dist))) + \" - \" + str(identity), (x1, y1 - 20), \n",
    "#                 cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1) #lineType=cv2.LINE_AA)        \n",
    "\n",
    "#     cv2.imshow('Video', frame)\n",
    "#     cv2.waitKey(40)\n",
    "\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# video_capture.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
